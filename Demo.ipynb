{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSCON 2019 Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections\n",
    "* Required tools\n",
    " * Docker and k8s: download and install [docker desktop](https://www.docker.com/products/docker-desktop)\n",
    "  * Enable kubernetes in docker desktop (preferences->kubernetes->enable)\n",
    " * download and install [redis](https://redis.io/download) (>5.0)\n",
    " * download and install [kafka](https://kafka.apache.org/downloads)\n",
    "* Model\n",
    " * Train the model: Use the train model (train_model.ipynb)[notebook]\n",
    " * Copy the model to the other pods\n",
    " * Deploy model to kubeflow (seldon)\n",
    "* Run kafka\n",
    " * Run producer\n",
    "  * Deploy consumer to kubernetes\n",
    "* Run redis (single instance)\n",
    " * Run redis-streams consumer\n",
    "* Build and deploy consumer pods\n",
    "* Publish some raw features and confirm output\n",
    " \n",
    "(It is assumed that you run the notebook from the oscon_demo directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model from the [notebook](train_model.ipynb)\n",
    "Then copy the model to the pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cp sklearn_housing_predictor_model/example_model.pkl invoke_model_direct/\n",
    "%cp sklearn_housing_predictor_model/example_model.pkl invoke_model_seldon/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "!kill -9 `ps -ef|grep -i kafka|grep oscon_demo|awk '{print $2}'`\n",
    "!rm -rf kafka_2.11-2.2.0*\n",
    "!rm -rf /tmp/kafka-logs\n",
    "!rm -rf /tmp/zookeeper\n",
    "!docker stop test-redis\n",
    "!docker rm test-redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and deploy the model to seldon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build\n",
    "%cd sklearn_housing_predictor_model/\n",
    "!sh build_local_img_model.sh\n",
    "!sh deploy.sh\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the seldon model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd metrics/\n",
    "!sh test_local_seldon.sh\n",
    "%cd ..\n",
    "%killbgscripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and extract kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://mirrors.ocf.berkeley.edu/apache/kafka/2.2.0/kafka_2.11-2.2.0.tgz\n",
    "!tar zxvf kafka_2.11-2.2.0.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A kafka docker image here would make it simpler\n",
    "%cd kafka_2.11-2.2.0\n",
    "f = open(\"run_zk_and_kafka.sh\", \"a\")\n",
    "f.write(\"#!/bin/bash\\n\\n\")\n",
    "f.write(\"bin/zookeeper-server-start.sh config/zookeeper.properties &>zk.out &\\n\")\n",
    "f.write(\"sleep 5\\n\")\n",
    "f.write(\"bin/kafka-server-start.sh config/server.properties &>kafka.out &\\n\")\n",
    "f.close()\n",
    "!chmod 755 run_zk_and_kafka.sh\n",
    "\n",
    "import subprocess\n",
    "subprocess.call(['./run_zk_and_kafka.sh'])\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run --rm -it -p 6379:6379 --name test-redis -d redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and deploy containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw feature consumer pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd raw_kafka_feature_consumer_pod/\n",
    "!sh ./build_img.sh 0.1\n",
    "!sh ./deploy.sh\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct model invocation pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd invoke_model_direct/\n",
    "!sh ./build_local_img_model.sh 0.1\n",
    "!sh ./deploy.sh\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seldon model invocation pod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd invoke_model_seldon/\n",
    "!sh ./build_local_img_model.sh 0.1\n",
    "!sh ./deploy.sh\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, publish a set of raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaProducer\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from time import sleep\n",
    "\n",
    "# start our producer\n",
    "producer = KafkaProducer(bootstrap_servers=['localhost:9092'])\n",
    "\n",
    "# fetch and load the housing data set\n",
    "d = datasets.fetch_california_housing()\n",
    "\n",
    "# get a random row\n",
    "random_row = d.data[np.random.randint(len(d.data))]\n",
    "\n",
    "# for demo purposes, divide each geographical unit by 5 (to aggregate later)\n",
    "divided_features = np.concatenate((random_row[0:6] / 5, np.array([random_row[6], random_row[7]])), axis=0)\n",
    "short_feature_names = d.feature_names\n",
    "features_and_names = np.array([short_feature_names, divided_features])\n",
    "\n",
    "# publish divided features\n",
    "for i in range(0, 5):\n",
    "    future = producer.send('housing-topic', features_and_names.tobytes())\n",
    "print('produced 5 messages for lat/lon=', np.array([random_row[6], random_row[7]]))\n",
    "sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm predicts are flowing through the components\n",
    "\n",
    "For **housing-kafka-consumer** it should look like \n",
    "\n",
    "`publishing aggregated features to stream for lat/lon  40.69 / -121.83`\n",
    "\n",
    "And for **housing-predictor-(direct | seldon)** it should be the same for each, like\n",
    "\n",
    "`direct msg_id= b'1564016621676-0' , lat/lon= [40.69, -121.83] , prediction = $ 117253.33333333331`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl -n kubeflow logs `kubectl -n kubeflow get pods|grep 'housing-kafka-consumer' |awk '{print $1}'`|tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl -n kubeflow logs `kubectl -n kubeflow get pods|grep 'housing-predictor-seldon' |awk '{print $1}'`|tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl -n kubeflow logs `kubectl -n kubeflow get pods|grep 'housing-predictor-direct' |awk '{print $1}'`|tail -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running a constant producer\n",
    "\n",
    "And if you want to run a constant producer and watch the logs, just run `row_kafka_feature_producer/producer.py` manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
