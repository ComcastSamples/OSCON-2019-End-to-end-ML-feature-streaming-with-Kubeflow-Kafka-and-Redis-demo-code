{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures, StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, save, confirm predictions and some timing\n",
    "In this notebook we will\n",
    "* Train the model (**make sure the model is trained with python 3.6**)\n",
    "* Save the model (in pickle format)\n",
    "* Confirm the prediction distributions\n",
    "* Generate some rough batch timings for invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data set\n",
    "d = datasets.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "\n",
    "def test_train_split(df, class_name):\n",
    "    # create test/train split\n",
    "    (test_s, train_s) = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    # get class column\n",
    "    train_x = train_s.drop([class_name], axis=1)\n",
    "    test_x = test_s.drop([class_name], axis=1)\n",
    "    train_y = train_s[[class_name]]\n",
    "    test_y = test_s[[class_name]]\n",
    "\n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "\n",
    "def train(train_x, train_y):\n",
    "    # clf = LinearRegression() # r^2 ~ 0.6\n",
    "    clf = RandomForestRegressor(n_estimators=100) # r^2 ~ 0.73\n",
    "    clf.fit(train_x, train_y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def train_pred_and_eval(train_x, test_x, train_y, test_y):\n",
    "    # train\n",
    "    clf = train(train_x, train_y)\n",
    "    # predict\n",
    "    pred = clf.predict(test_x)\n",
    "    # mse\n",
    "    mse = mean_squared_error(test_y, pred)\n",
    "    # eval metrics\n",
    "    rmse, mae, r2 = eval_metrics(test_y, pred)\n",
    "    return clf, mse, rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the data into a single data frame\n",
    "df = pd.DataFrame(d.data, columns=d.feature_names)\n",
    "new_feature_names = d.feature_names\n",
    "new_feature_names.append('MedHouseVal')\n",
    "df['MedHouseVal'] = d.target\n",
    "\n",
    "# make a copy of the original\n",
    "df_orig = df.copy()\n",
    "\n",
    "# normalize the data\n",
    "df = pd.DataFrame(MinMaxScaler().fit_transform(X=df), columns=new_feature_names)\n",
    "\n",
    "# shuffle\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_x, test_x, train_y, test_y = test_train_split(df, 'MedHouseVal')\n",
    "(clf, mse, rmse, mae, r2) = train_pred_and_eval(train_x, test_x, train_y, test_y)\n",
    "print(\"data (original), MSE: %.2f, RMSE: %.2f, MAE: %.2f, r^2: %.2f\" % (mse, rmse, mae, r2))\n",
    "\n",
    "# so ~75% of the observed variation in median house value for a given area is explained by the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "model_file = 'example_model.pkl'\n",
    "pickle.dump(clf, open(model_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats about the target variable distribution\n",
    "(df_orig['MedHouseVal']*100_000).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and test\n",
    "m = pickle.load(open(model_file, 'rb'))\n",
    "\n",
    "# get a scalar for our median house value\n",
    "med_house_val_scaler = MinMaxScaler().fit(df_orig['MedHouseVal'].values.reshape(-1, 1))\n",
    "print(med_house_val_scaler)\n",
    "\n",
    "# make a prediction and output it in dollars of 100,000\n",
    "m.predict(test_x.sample())\n",
    "#med_house_val_scaler.inverse_transform([m.predict(test_x.sample())])*100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_orig['MedHouseVal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(med_house_val_scaler.inverse_transform(m.predict(test_x).reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "s = \"\"\"\n",
    "m.predict(s_features)\n",
    "\"\"\"\n",
    "\n",
    "times = [None] * 4\n",
    "c = 0\n",
    "for iters in [1,10,1000,10000]:\n",
    "    x = []\n",
    "    y = []\n",
    "    for batchsize in [10,100,1000]:\n",
    "        time_elapsed = 0\n",
    "        count = 0\n",
    "        while count <= iters:\n",
    "            count += batchsize\n",
    "            s_features = test_x.sample(batchsize).values.tolist()\n",
    "            time_elapsed += timeit.timeit(s, 'from __main__ import ' + ', '.join(globals()), number=1)\n",
    "        if batchsize >= 1000:\n",
    "            print('iters=',iters,'\\tbatchsize=',batchsize,'\\ttime_elapsed=',time_elapsed)\n",
    "        else:\n",
    "            print('iters=',iters,'\\tbatchsize=',batchsize,'\\t\\ttime_elapsed=',time_elapsed)\n",
    "        x.append(batchsize)\n",
    "        y.append(time_elapsed)\n",
    "    times[c] = [x,y]\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim(0,.8)\n",
    "plt.plot(times[0][0], times[0][1], 'r', times[1][0], times[1][1], 'b', times[2][0], times[2][1], 'g', times[3][0], times[3][1], 'y')\n",
    "plt.xlabel('batch size')\n",
    "plt.ylabel('time elapsed (seconds)')\n",
    "plt.title('model invocation times')\n",
    "plt.legend(('1 iteration', '10 iterations', '1000 iterations', '10000 iterations'), loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times2 = [None] * 5\n",
    "c = 0\n",
    "for iters in [1,10,1000,10000,50000]:\n",
    "    x = []\n",
    "    y = []\n",
    "    for batchsize in [100,500,1000,2500,5000,7500,10000]:\n",
    "        time_elapsed = 0\n",
    "        count = 0\n",
    "        while count <= iters:\n",
    "            count += batchsize\n",
    "            s_features = test_x.sample(batchsize).values.tolist()\n",
    "            time_elapsed += timeit.timeit(s, 'from __main__ import ' + ', '.join(globals()), number=1)\n",
    "        if batchsize >= 1000:\n",
    "            print('iters=',iters,'\\tbatchsize=',batchsize,'\\ttime_elapsed=',time_elapsed)\n",
    "        else:\n",
    "            print('iters=',iters,'\\tbatchsize=',batchsize,'\\t\\ttime_elapsed=',time_elapsed)\n",
    "        x.append(batchsize)\n",
    "        y.append(time_elapsed)\n",
    "    times2[c] = [x,y]\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.ylim(0,1.5)\n",
    "plt.plot(times2[0][0], times2[0][1], 'r', times2[1][0], times2[1][1], 'b', times2[2][0], times2[2][1], 'g', times2[3][0], times2[3][1], 'y', times2[4][0], times2[4][1], 'b')\n",
    "plt.xlabel('batch size')\n",
    "plt.ylabel('time elapsed (seconds)')\n",
    "plt.title('model invocation times')\n",
    "plt.legend(('1 iteration', '10 iterations', '1000 iterations', '10000 iterations', '50000 iterations'), loc='upper right')\n",
    "plt.axhline(y=1, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = open('samples.10', 'w')\n",
    "#f.write(str(test_x.sample(10).values.reshape(1,-1).tolist()[0]))\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
